{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c63bc0b2725c42b6b10d876e89e3d30d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6c2866f885e241019bdf53d27e61f601",
              "IPY_MODEL_5a0824a0e78141208ac56839abcd8531",
              "IPY_MODEL_87785dea26b348e1aaa1019147a63f91",
              "IPY_MODEL_d304af25c65e4c62bab7c6c71a9a5cbb"
            ],
            "layout": "IPY_MODEL_b2fd8c526e904c5c9736c0b78b85d3cf",
            "tabbable": null,
            "tooltip": null
          }
        },
        "6c2866f885e241019bdf53d27e61f601": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "gemini-2.5-flash",
              "gemini-2.5-pro",
              "gemini-2.0-flash",
              "gemini-2.0-flash-lite"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "DropdownView",
            "description": "Base model:",
            "description_allow_html": false,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_6fa9bb9c5445498f9298b30acce4dc03",
            "style": "IPY_MODEL_5d10a451955147d6a7badf7785d7077e",
            "tabbable": null,
            "tooltip": null
          }
        },
        "5a0824a0e78141208ac56839abcd8531": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0f9e99b807684d738e7942afad07edb5",
              "IPY_MODEL_f4a12a6700a140de9e124938d49fcf90",
              "IPY_MODEL_0d501965d4ff44f68887f63e9b00b4fc"
            ],
            "layout": "IPY_MODEL_2fb70ca3b7a64b2f9a89827e457eee9b",
            "tabbable": null,
            "tooltip": null
          }
        },
        "87785dea26b348e1aaa1019147a63f91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ButtonView",
            "button_style": "primary",
            "description": "Apply settings",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_7a17a647b5ef4dfeb3773c352aa5c769",
            "style": "IPY_MODEL_441707709e484dd09f3272812a9ce81f",
            "tabbable": null,
            "tooltip": null
          }
        },
        "d304af25c65e4c62bab7c6c71a9a5cbb": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_007d05b5ccc2470ba25d1a91d814db96",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "âœ” Settings applied\n",
                  "Base model: gemini-2.5-flash\n",
                  "Epochs: 2\n",
                  "Adapter: SMALL (int: 4 )\n",
                  "LR multiplier: 1.0\n"
                ]
              }
            ],
            "tabbable": null,
            "tooltip": null
          }
        },
        "b2fd8c526e904c5c9736c0b78b85d3cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fa9bb9c5445498f9298b30acce4dc03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "420px"
          }
        },
        "5d10a451955147d6a7badf7785d7077e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f9e99b807684d738e7942afad07edb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntTextModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "IntTextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "IntTextView",
            "continuous_update": false,
            "description": "Epochs:",
            "description_allow_html": false,
            "disabled": false,
            "layout": "IPY_MODEL_56046e918276427b9f32089172035cef",
            "step": 1,
            "style": "IPY_MODEL_5c03bba6f8164bfc83df88c199d21c6d",
            "tabbable": null,
            "tooltip": null,
            "value": 2
          }
        },
        "f4a12a6700a140de9e124938d49fcf90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "Tiny (1)",
              "Small (4)",
              "Medium (8)",
              "Large (16)"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "DropdownView",
            "description": "Adapter:",
            "description_allow_html": false,
            "disabled": false,
            "index": 1,
            "layout": "IPY_MODEL_bfa3ba5057d14290b95c0b5e53f2acd6",
            "style": "IPY_MODEL_76e75b23ae7d4a70aec2233a61c2bbf1",
            "tabbable": null,
            "tooltip": null
          }
        },
        "0d501965d4ff44f68887f63e9b00b4fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatTextModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatTextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "FloatTextView",
            "continuous_update": false,
            "description": "LR Mult:",
            "description_allow_html": false,
            "disabled": false,
            "layout": "IPY_MODEL_92fc879f0e9240ac973abc9b041d4efd",
            "step": null,
            "style": "IPY_MODEL_3dba8e312aaf450596549785205744c9",
            "tabbable": null,
            "tooltip": null,
            "value": 1
          }
        },
        "2fb70ca3b7a64b2f9a89827e457eee9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a17a647b5ef4dfeb3773c352aa5c769": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "441707709e484dd09f3272812a9ce81f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_family": null,
            "font_size": null,
            "font_style": null,
            "font_variant": null,
            "font_weight": null,
            "text_color": null,
            "text_decoration": null
          }
        },
        "56046e918276427b9f32089172035cef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "180px"
          }
        },
        "5c03bba6f8164bfc83df88c199d21c6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bfa3ba5057d14290b95c0b5e53f2acd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "220px"
          }
        },
        "76e75b23ae7d4a70aec2233a61c2bbf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92fc879f0e9240ac973abc9b041d4efd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "180px"
          }
        },
        "3dba8e312aaf450596549785205744c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "007d05b5ccc2470ba25d1a91d814db96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4d18302405947719e09f4bc67e95e91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5b45755e07754979a7b3a2ac4572215c",
              "IPY_MODEL_8ace3e0d3b1841ed8e3e20e9fe8c12cf",
              "IPY_MODEL_696e3dbf5803443bbc74761fec978185"
            ],
            "layout": "IPY_MODEL_f7605b3ec1bf4d7489bb662c0c6415e7",
            "tabbable": null,
            "tooltip": null
          }
        },
        "5b45755e07754979a7b3a2ac4572215c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "Yes",
              "No"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "DropdownView",
            "description": "Shuffle?",
            "description_allow_html": false,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_bd2dbb748a5d4ccb9b7475093f19e06c",
            "style": "IPY_MODEL_41140a6a8e5b4e70ba0c0e8219f3ef2e",
            "tabbable": null,
            "tooltip": null
          }
        },
        "8ace3e0d3b1841ed8e3e20e9fe8c12cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ButtonView",
            "button_style": "primary",
            "description": "Apply",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_8ad74a261fd34dccb723012debfc366d",
            "style": "IPY_MODEL_379904a003134604a9ace2bcd86cadd6",
            "tabbable": null,
            "tooltip": null
          }
        },
        "696e3dbf5803443bbc74761fec978185": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_83e790dfa36747de8f72ede5730f35ae",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Done. Shuffle: Yes\n",
                  "ds_train: 15 rows\n",
                  "ds_val:   10 rows\n",
                  "ds_test:  10 rows\n"
                ]
              }
            ],
            "tabbable": null,
            "tooltip": null
          }
        },
        "f7605b3ec1bf4d7489bb662c0c6415e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd2dbb748a5d4ccb9b7475093f19e06c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41140a6a8e5b4e70ba0c0e8219f3ef2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ad74a261fd34dccb723012debfc366d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "379904a003134604a9ace2bcd86cadd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_family": null,
            "font_size": null,
            "font_style": null,
            "font_variant": null,
            "font_weight": null,
            "text_color": null,
            "text_decoration": null
          }
        },
        "83e790dfa36747de8f72ede5730f35ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-Tune Multi-Modal (image+text) Gemini model for Visual Q+A\n",
        "\n",
        "\n",
        "CS 663: Group 6"
      ],
      "metadata": {
        "id": "fUbBOcY3XB7l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Colab shows how to fine-tune Gemini for the TACO dataset to categorize an image into a certain category: Plastic, Paper, Metal, Glass, or Organic."
      ],
      "metadata": {
        "id": "rC8rkLXhSlgy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 1: Installs (HF datasets + Vertex AI libs)"
      ],
      "metadata": {
        "id": "7BrodReSXQ9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install libraries (pin versions so no conflicts like script-based HF datasets load cleanly)\n",
        "# --- Clean out known conflict sources (safe to skip if not present)\n",
        "!pip -q uninstall -y vertexai gcsfs fsspec google-adk\n",
        "\n",
        "# --- Pass A: HF + datasets stack (lets `datasets` pick compatible fsspec)\n",
        "!pip -q install -U \\\n",
        "  \"datasets==2.19.2\" \\\n",
        "  \"huggingface_hub>=0.24.0\" \\\n",
        "  \"tqdm>=4.66.0\" \\\n",
        "  \"Pillow>=10.4.0\" \\\n",
        "  \"ipywidgets>=8.1.2\"\n",
        "\n",
        "# --- Pass B: Google libs (no separate `vertexai` package needed)\n",
        "!pip -q install -U \\\n",
        "  \"google-genai>=0.3.0\" \\\n",
        "  \"google-cloud-aiplatform>=1.71,<2\" \\\n",
        "  \"google-cloud-storage>=2.17.0\"\n",
        "\n",
        "import datasets, fsspec, google.cloud.aiplatform as aiplatform\n",
        "import vertexai  # provided by google-cloud-aiplatform\n",
        "print(\"datasets:\", datasets.__version__)\n",
        "print(\"fsspec:\", fsspec.__version__)\n",
        "print(\"aiplatform:\", aiplatform.__version__)\n",
        "print(\"vertexai module OK\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4p9o2vViMag",
        "outputId": "af661b0c-28a8-4d85-9b76-c748d899eae5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping vertexai as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m542.1/542.1 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m516.1/516.1 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 2.29.1 requires gcsfs!=2025.5.0,>=2023.3.0, which is not installed.\n",
            "transformers 4.57.2 requires huggingface-hub<1.0,>=0.34.0, but you have huggingface-hub 1.1.6 which is incompatible.\n",
            "gradio 5.50.0 requires pillow<12.0,>=8.0, but you have pillow 12.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mdatasets: 2.19.2\n",
            "fsspec: 2024.3.1\n",
            "aiplatform: 1.128.0\n",
            "vertexai module OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 2: Auth + project/region + buckets\n",
        "\n"
      ],
      "metadata": {
        "id": "AL_cRtoeXYjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Authenticate and set project/region/bucket from Colab userdata (no GUI, no bucket modification)\n",
        "\n",
        "# ðŸ”‘ Secrets expected in Colab userdata:\n",
        "# - GOOGLE_CLOUD_PROJECT: Your Google Cloud project ID (Cloud Console â†’ \"Project Info\")\n",
        "# - GOOGLE_DEFAULT_REGION: Region for Vertex AI and storage bucket (e.g., \"us-central1\")\n",
        "# - GOOGLE_DEFAULT_BUCKET: The exact GCS bucket to use (will NOT be modified)\n",
        "\n",
        "# ðŸ“‚ GCS_PREFIX:\n",
        "# - A timestamped folder-like prefix for organizing run data within the existing bucket.\n",
        "\n",
        "# 1) Authenticate Colab with your Google account\n",
        "from google.colab import auth as colab_auth\n",
        "colab_auth.authenticate_user()\n",
        "\n",
        "# 2) Read secrets from Colab userdata\n",
        "from google.colab import userdata\n",
        "import datetime\n",
        "\n",
        "PROJECT_ID = userdata.get('GOOGLE_CLOUD_PROJECT')\n",
        "REGION = userdata.get('GOOGLE_DEFAULT_REGION') or \"us-central1\"\n",
        "GCS_BUCKET = userdata.get('GOOGLE_DEFAULT_BUCKET')\n",
        "\n",
        "assert PROJECT_ID, \"âŒ Missing GOOGLE_CLOUD_PROJECT in userdata.\"\n",
        "assert GCS_BUCKET, \"âŒ Missing GOOGLE_DEFAULT_BUCKET in userdata.\"\n",
        "\n",
        "# 3) Initialize Vertex AI\n",
        "import vertexai\n",
        "vertexai.init(project=PROJECT_ID, location=REGION)\n",
        "\n",
        "# 4) Create unique prefix for this run\n",
        "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "GCS_PREFIX = f\"multimodal_sft_{timestamp}\"\n",
        "\n",
        "# 5) Helper for building gs:// URIs\n",
        "def gs_uri(*parts):\n",
        "    return \"gs://\" + \"/\".join([GCS_BUCKET] + [p.strip(\"/\") for p in parts])\n",
        "\n",
        "# 6) Save globally for reuse\n",
        "globals()[\"PROJECT_ID\"] = PROJECT_ID\n",
        "globals()[\"REGION\"] = REGION\n",
        "globals()[\"GCS_BUCKET\"] = GCS_BUCKET\n",
        "globals()[\"GCS_PREFIX\"] = GCS_PREFIX\n",
        "globals()[\"gs_uri\"] = gs_uri\n",
        "\n",
        "# 7) Print summary\n",
        "print(\"âœ… Environment initialized\")\n",
        "print(\"âœ… Project:\", PROJECT_ID)\n",
        "print(\"âœ… Region:\", REGION)\n",
        "print(\"âœ… Bucket:\", f\"gs://{GCS_BUCKET}\")\n",
        "print(\"ðŸ“‚ Prefix:\", GCS_PREFIX)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYKMm9bXFufD",
        "outputId": "7fb99fd2-df3c-437f-8222-fb6c1e4535ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Environment initialized\n",
            "âœ… Project: project-2-group-6\n",
            "âœ… Region: us-central1\n",
            "âœ… Bucket: gs://my-gemini-sft-bucket-group-6\n",
            "ðŸ“‚ Prefix: multimodal_sft_20251130_040559\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 3: Choose a multimodal base model + \"tuning knobs\"\n"
      ],
      "metadata": {
        "id": "eVmaWIfQaJla"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 3: Choose base Gemini model + tuning params (with widgets)\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "# Use prior values if they exist, else defaults\n",
        "_default_base   = globals().get(\"BASE_MODEL\", \"gemini-2.5-flash\")\n",
        "_default_epochs = int(globals().get(\"EPOCHS\", 2))\n",
        "_default_adapt  = str(globals().get(\"ADAPTER_SIZE\", \"SMALL\"))\n",
        "_default_lrm    = float(globals().get(\"LEARNING_RATE_MULTIPLIER\", 1.0))\n",
        "\n",
        "# Adapter size mapping (string -> integer bottleneck size)\n",
        "_ADAPTER_TO_INT = {\"TINY\": 1, \"SMALL\": 4, \"MEDIUM\": 8, \"LARGE\": 16}\n",
        "\n",
        "# Widgets\n",
        "base_dd = widgets.Dropdown(\n",
        "    options=[\"gemini-2.5-flash\",\"gemini-2.5-pro\",\"gemini-2.0-flash\",\"gemini-2.0-flash-lite\"],\n",
        "    value=_default_base,\n",
        "    description=\"Base model:\",\n",
        "    layout=widgets.Layout(width=\"420px\"),\n",
        ")\n",
        "\n",
        "epochs_in = widgets.IntText(\n",
        "    value=_default_epochs, description=\"Epochs:\", min=1, step=1, layout=widgets.Layout(width=\"180px\")\n",
        ")\n",
        "\n",
        "adapter_dd = widgets.Dropdown(\n",
        "    options=[(\"Tiny (1)\", \"TINY\"), (\"Small (4)\", \"SMALL\"), (\"Medium (8)\", \"MEDIUM\"), (\"Large (16)\", \"LARGE\")],\n",
        "    value=_default_adapt,\n",
        "    description=\"Adapter:\",\n",
        "    layout=widgets.Layout(width=\"220px\"),\n",
        ")\n",
        "\n",
        "lrm_in = widgets.FloatText(\n",
        "    value=_default_lrm, description=\"LR Mult:\", layout=widgets.Layout(width=\"180px\")\n",
        ")\n",
        "\n",
        "apply_btn = widgets.Button(description=\"Apply settings\", button_style=\"primary\")\n",
        "out = widgets.Output()\n",
        "\n",
        "def on_apply(_):\n",
        "    with out:\n",
        "        clear_output()\n",
        "        # Write selections into globals so later cells see them\n",
        "        globals()[\"BASE_MODEL\"] = base_dd.value\n",
        "        globals()[\"EPOCHS\"] = int(epochs_in.value)\n",
        "        globals()[\"ADAPTER_SIZE\"] = adapter_dd.value\n",
        "        globals()[\"ADAPTER_SIZE_INT\"] = _ADAPTER_TO_INT[adapter_dd.value]  # for APIs needing an int\n",
        "        globals()[\"LEARNING_RATE_MULTIPLIER\"] = float(lrm_in.value)\n",
        "\n",
        "        print(\"âœ” Settings applied\")\n",
        "        print(\"Base model:\", BASE_MODEL)\n",
        "        print(\"Epochs:\", EPOCHS)\n",
        "        print(\"Adapter:\", ADAPTER_SIZE, \"(int:\", ADAPTER_SIZE_INT, \")\")\n",
        "        print(\"LR multiplier:\", LEARNING_RATE_MULTIPLIER)\n",
        "\n",
        "apply_btn.on_click(on_apply)\n",
        "\n",
        "ui = widgets.VBox([\n",
        "    base_dd,\n",
        "    widgets.HBox([epochs_in, adapter_dd, lrm_in]),\n",
        "    apply_btn,\n",
        "    out\n",
        "])\n",
        "\n",
        "display(ui)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200,
          "referenced_widgets": [
            "c63bc0b2725c42b6b10d876e89e3d30d",
            "6c2866f885e241019bdf53d27e61f601",
            "5a0824a0e78141208ac56839abcd8531",
            "87785dea26b348e1aaa1019147a63f91",
            "d304af25c65e4c62bab7c6c71a9a5cbb",
            "b2fd8c526e904c5c9736c0b78b85d3cf",
            "6fa9bb9c5445498f9298b30acce4dc03",
            "5d10a451955147d6a7badf7785d7077e",
            "0f9e99b807684d738e7942afad07edb5",
            "f4a12a6700a140de9e124938d49fcf90",
            "0d501965d4ff44f68887f63e9b00b4fc",
            "2fb70ca3b7a64b2f9a89827e457eee9b",
            "7a17a647b5ef4dfeb3773c352aa5c769",
            "441707709e484dd09f3272812a9ce81f",
            "56046e918276427b9f32089172035cef",
            "5c03bba6f8164bfc83df88c199d21c6d",
            "bfa3ba5057d14290b95c0b5e53f2acd6",
            "76e75b23ae7d4a70aec2233a61c2bbf1",
            "92fc879f0e9240ac973abc9b041d4efd",
            "3dba8e312aaf450596549785205744c9",
            "007d05b5ccc2470ba25d1a91d814db96"
          ]
        },
        "id": "bIa_7BLUcuxS",
        "outputId": "baab16d0-2ac5-4581-a152-b29a58592a93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Dropdown(description='Base model:', layout=Layout(width='420px'), options=('gemini-2.5-flash', â€¦"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c63bc0b2725c42b6b10d876e89e3d30d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 3.1 adapter name convert to integer\n"
      ],
      "metadata": {
        "id": "dDVZd2F_vChx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 3.1 â€” Map ADAPTER_SIZE to integer (SDK expects 1,4,8,16)\n",
        "# Accepts either labels (\"TINY\",\"SMALL\",\"MEDIUM\",\"LARGE\") or integers/strings 1/4/8/16\n",
        "\n",
        "_ADAPTER_LABEL_TO_INT = {\n",
        "    \"TINY\": 1, \"SMALL\": 4, \"MEDIUM\": 8, \"LARGE\": 16,\n",
        "    \"tiny\": 1, \"small\": 4, \"medium\": 8, \"large\": 16,\n",
        "}\n",
        "\n",
        "def normalize_adapter_size(x):\n",
        "    if isinstance(x, (int, float)):\n",
        "        xi = int(x)\n",
        "        if xi in (1, 4, 8, 16):\n",
        "            return xi\n",
        "    if isinstance(x, str):\n",
        "        x = x.strip()\n",
        "        if x.isdigit() and int(x) in (1, 4, 8, 16):\n",
        "            return int(x)\n",
        "        if x in _ADAPTER_LABEL_TO_INT:\n",
        "            return _ADAPTER_LABEL_TO_INT[x]\n",
        "    raise ValueError(\"Invalid ADAPTER_SIZE. Use one of {1,4,8,16} or labels TINY/SMALL/MEDIUM/LARGE.\")\n",
        "\n",
        "ADAPTER_SIZE_NUM = normalize_adapter_size(ADAPTER_SIZE)\n",
        "print(\"âœ… Using adapter_size:\", ADAPTER_SIZE_NUM)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T10tBj4-vHRU",
        "outputId": "5894b4aa-5710-4cbe-a28e-eb8cf117485c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Using adapter_size: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 4: Import dataset from Google Drive and select train, validation, and test samples"
      ],
      "metadata": {
        "id": "EkcRxJWXXhoZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Important: You must have a folder in your Google Drive called TACO where the dataset is*\n",
        "\n",
        "Here is a link to an drive that you can copy to your own drive: https://drive.google.com/drive/u/1/folders/1YFmuOqXV_8k6Srm4_2oEVKblsWaNWg3a\n",
        "\n"
      ],
      "metadata": {
        "id": "JgpttGXDob8X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os, json\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "# -----------------------------\n",
        "# Configure sample sizes here\n",
        "N_TRAIN = 15\n",
        "N_VAL   = 10\n",
        "N_TEST  = 10\n",
        "# -----------------------------\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to your TACO images folder\n",
        "IMAGES_DIR = \"/content/drive/MyDrive/TACO\"\n",
        "\n",
        "answers_path = os.path.join(IMAGES_DIR, \"answers.json\")\n",
        "with open(answers_path, \"r\") as f:\n",
        "    answers = json.load(f)\n",
        "\n",
        "# Build DataFrame with image paths\n",
        "image_files = sorted([f for f in os.listdir(IMAGES_DIR) if f.lower().endswith(('.jpg','.png'))])\n",
        "records = []\n",
        "for f in image_files:\n",
        "    path = os.path.join(IMAGES_DIR, f)\n",
        "    answer = answers.get(f, \"Unknown\")\n",
        "    try:\n",
        "        img = Image.open(path).convert(\"RGB\")\n",
        "        records.append({\n",
        "            \"image\": img,\n",
        "            \"question\": \"What can the objects in this image be reused for?\",\n",
        "            \"answer\": answer\n",
        "        })\n",
        "    except Exception as e:\n",
        "        print(f\"Skipping {f}: {e}\")\n",
        "\n",
        "df = pd.DataFrame(records)\n",
        "print(f\"Loaded {len(df)} images\")\n",
        "\n",
        "# -----------------------------\n",
        "# Widget setup\n",
        "shuffle_dd = widgets.Dropdown(options=['Yes', 'No'], value='Yes', description='Shuffle?')\n",
        "apply_btn  = widgets.Button(description='Apply', button_style='primary')\n",
        "out        = widgets.Output()\n",
        "\n",
        "def _normalize_schema(df):\n",
        "    # Already has 'question', 'answer', 'image'\n",
        "    return df[['question', 'answer', 'image']].reset_index(drop=True)\n",
        "\n",
        "def _process(shuffle_choice: str):\n",
        "    # Shuffle if requested\n",
        "    data = df.sample(frac=1, random_state=42).reset_index(drop=True) if shuffle_choice == 'Yes' else df.copy()\n",
        "    total = len(data)\n",
        "\n",
        "    n_train = min(N_TRAIN, total)\n",
        "    n_val   = min(N_VAL, total - n_train)\n",
        "    n_test  = min(N_TEST, total - n_train - n_val)\n",
        "\n",
        "    ds_train = _normalize_schema(data.iloc[:n_train])\n",
        "    ds_val   = _normalize_schema(data.iloc[n_train:n_train+n_val])\n",
        "    ds_test  = _normalize_schema(data.iloc[n_train+n_val:n_train+n_val+n_test])\n",
        "\n",
        "    globals()['ds_train'] = ds_train\n",
        "    globals()['ds_val']   = ds_val\n",
        "    globals()['ds_test']  = ds_test\n",
        "\n",
        "    return ds_train, ds_val, ds_test\n",
        "\n",
        "def _on_apply(_):\n",
        "    with out:\n",
        "        clear_output(wait=True)\n",
        "        t, v, u = _process(shuffle_dd.value)\n",
        "        globals()['ds'] = {\n",
        "            \"train\": globals()['ds_train'],\n",
        "            \"validation\": globals()['ds_val'],\n",
        "            \"test\": globals()['ds_test']\n",
        "        }\n",
        "        print(f\"Done. Shuffle: {shuffle_dd.value}\")\n",
        "        print(f\"ds_train: {len(t)} rows\")\n",
        "        print(f\"ds_val:   {len(v)} rows\")\n",
        "        print(f\"ds_test:  {len(u)} rows\")\n",
        "\n",
        "apply_btn.on_click(_on_apply)\n",
        "display(widgets.VBox([shuffle_dd, apply_btn, out]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185,
          "referenced_widgets": [
            "b4d18302405947719e09f4bc67e95e91",
            "5b45755e07754979a7b3a2ac4572215c",
            "8ace3e0d3b1841ed8e3e20e9fe8c12cf",
            "696e3dbf5803443bbc74761fec978185",
            "f7605b3ec1bf4d7489bb662c0c6415e7",
            "bd2dbb748a5d4ccb9b7475093f19e06c",
            "41140a6a8e5b4e70ba0c0e8219f3ef2e",
            "8ad74a261fd34dccb723012debfc366d",
            "379904a003134604a9ace2bcd86cadd6",
            "83e790dfa36747de8f72ede5730f35ae"
          ]
        },
        "id": "ShpEMT8xocTu",
        "outputId": "db3f69b5-ad8f-4438-f6e1-f1eda9e2d645"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Loaded 35 images\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Dropdown(description='Shuffle?', options=('Yes', 'No'), value='Yes'), Button(button_style='primâ€¦"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b4d18302405947719e09f4bc67e95e91"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display a random image"
      ],
      "metadata": {
        "id": "7Acbq8Rr_nmm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "\n",
        "# display a random training example\n",
        "print('QUESTION:', ds_train.iloc[4]['question'])\n",
        "display(ds_train.iloc[4]['image'])\n",
        "print('ANSWER:', ds_train.iloc[4]['answer'])\n"
      ],
      "metadata": {
        "id": "RrcAuvkepO7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 5: Build Gemini SFT JSONL (image + question â†’ answer) and upload to GCS\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sn4tAs6hcZRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build Gemini SFT JSONL (robust row handling) and upload to GCS\n",
        "import os, io, json, pathlib, tempfile, mimetypes, requests\n",
        "from typing import Any, Dict, List, Tuple, Optional\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from google.cloud import storage\n",
        "import pandas as pd\n",
        "\n",
        "# -------------------------\n",
        "# Preconditions / globals\n",
        "# -------------------------\n",
        "assert 'ds' in globals(), \"Run Step 4 to load a dataset into `ds` first.\"\n",
        "assert 'GCS_BUCKET' in globals() and 'PROJECT_ID' in globals(), \"Run the auth/setup cell first.\"\n",
        "\n",
        "# SELECTED_HF_NAME should be set in Step 4; derive a fallback if not.\n",
        "if 'SELECTED_HF_NAME' not in globals() or not SELECTED_HF_NAME:\n",
        "    SELECTED_HF_NAME = (\n",
        "        getattr(ds, 'builder_name', None)\n",
        "        or getattr(getattr(next(iter(ds.values())), 'info', None), 'builder_name', None)\n",
        "        or \"dataset\"\n",
        "    )\n",
        "\n",
        "# TRAIN/VAL split names: respect existing globals; otherwise pick from ds keys\n",
        "available_splits = list(ds.keys())\n",
        "def _pick_train(keys):\n",
        "    for k in (\"train\",\"training\",\"Train\",\"TRAIN\"):\n",
        "        if k in keys: return k\n",
        "    return keys[0] if keys else \"train\"\n",
        "def _pick_val(keys):\n",
        "    for k in (\"validation\",\"val\",\"dev\",\"test\",\"Test\",\"TEST\"):\n",
        "        if k in keys: return k\n",
        "    return \"train\"\n",
        "\n",
        "if 'TRAIN_SPLIT' not in globals(): TRAIN_SPLIT = _pick_train(available_splits)\n",
        "if 'VAL_SPLIT'   not in globals(): VAL_SPLIT   = _pick_val(available_splits)\n",
        "\n",
        "# Example caps: use UI-provided N_TRAIN/N_VAL if present; else safe fallbacks\n",
        "MAX_TRAIN_EXAMPLES = globals().get('N_TRAIN', 1000)\n",
        "MAX_VAL_EXAMPLES   = globals().get('N_VAL',   200)\n",
        "\n",
        "# GCS object prefix for this run (if not set earlier)\n",
        "from datetime import datetime\n",
        "if 'GCS_PREFIX' not in globals() or not GCS_PREFIX:\n",
        "    GCS_PREFIX = f\"gemini_sft/{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
        "\n",
        "print(f\"Selected HF dataset: {SELECTED_HF_NAME}\")\n",
        "print(f\"Splits: train='{TRAIN_SPLIT}'  val='{VAL_SPLIT}'  (available: {available_splits})\")\n",
        "print(f\"Caps: MAX_TRAIN_EXAMPLES={MAX_TRAIN_EXAMPLES}  MAX_VAL_EXAMPLES={MAX_VAL_EXAMPLES}\")\n",
        "print(f\"GCS: gs://{GCS_BUCKET}/{GCS_PREFIX}/...\")\n",
        "\n",
        "# -------------------------\n",
        "# Utilities: access splits\n",
        "# -------------------------\n",
        "def _has(name: str) -> bool:\n",
        "    return name in globals()\n",
        "\n",
        "def _get_raw_split(name: str):\n",
        "    \"\"\"Return a row-indexable collection for the requested split.\"\"\"\n",
        "    if name == \"train\" and _has(\"ds_train\"): return ds_train\n",
        "    if name in (\"validation\", \"val\") and _has(\"ds_val\"): return ds_val\n",
        "    if name == \"test\" and _has(\"ds_test\"): return ds_test\n",
        "    if name in ds: return ds[name]\n",
        "    # fallback to common alternates\n",
        "    for alt in (\"validation\", \"val\", \"test\", \"train\"):\n",
        "        if alt in ds: return ds[alt]\n",
        "    raise ValueError(f\"Split '{name}' not found. Available: {list(ds.keys())}\")\n",
        "\n",
        "def _row_count(raw) -> int:\n",
        "    try:\n",
        "        return len(raw)\n",
        "    except Exception:\n",
        "        if isinstance(raw, dict) and raw:\n",
        "            try:\n",
        "                return min(len(v) for v in raw.values())\n",
        "            except Exception:\n",
        "                return 0\n",
        "        return 0\n",
        "\n",
        "def _hf_dataset_type():\n",
        "    try:\n",
        "        from datasets import Dataset as HFDataset\n",
        "        return HFDataset\n",
        "    except Exception:\n",
        "        return tuple()\n",
        "\n",
        "def _get_row(raw, i: int) -> Dict[str, Any]:\n",
        "    \"\"\"Return a dict-like example for row i across many container types.\"\"\"\n",
        "    HFDataset = _hf_dataset_type()\n",
        "\n",
        "    # HF Dataset\n",
        "    if HFDataset and isinstance(raw, HFDataset):\n",
        "        ex = raw[int(i)]\n",
        "        return ex if isinstance(ex, dict) else {\"value\": ex}\n",
        "\n",
        "    # pandas DataFrame\n",
        "    if isinstance(raw, pd.DataFrame):\n",
        "        return raw.iloc[int(i)].to_dict()\n",
        "\n",
        "    # list/tuple\n",
        "    if isinstance(raw, (list, tuple)):\n",
        "        ex = raw[int(i)]\n",
        "        return ex if isinstance(ex, dict) else {\"value\": ex}\n",
        "\n",
        "    # dict-of-lists\n",
        "    if isinstance(raw, dict) and all(isinstance(v, list) for v in raw.values()):\n",
        "        out = {}\n",
        "        for k, v in raw.items():\n",
        "            if len(v) > i:\n",
        "                out[k] = v[int(i)]\n",
        "        return out\n",
        "\n",
        "    # generic fallback\n",
        "    try:\n",
        "        ex = raw[int(i)]\n",
        "        return ex if isinstance(ex, dict) else {\"value\": ex}\n",
        "    except Exception:\n",
        "        return {\"value\": raw}\n",
        "\n",
        "# -------------------------\n",
        "# Field extraction (robust to arrays/lists)\n",
        "# -------------------------\n",
        "def _first_present(ex: Dict[str, Any], keys: List[str]):\n",
        "    for k in keys:\n",
        "        if k in ex and ex[k] is not None:\n",
        "            return ex[k]\n",
        "    return None\n",
        "\n",
        "def _to_list_of_str(v: Any) -> List[str]:\n",
        "    \"\"\"Coerce v into a list[str]. Handles str, list/tuple, ndarray, list[dict] with 'answer'.\"\"\"\n",
        "    try:\n",
        "        import numpy as np\n",
        "    except Exception:\n",
        "        np = None\n",
        "\n",
        "    if v is None:\n",
        "        return []\n",
        "\n",
        "    if isinstance(v, str):\n",
        "        return [v]\n",
        "\n",
        "    # HF 'answers' like [{\"answer\": \"x\"}, ...]\n",
        "    if isinstance(v, list) and v and isinstance(v[0], dict) and \"answer\" in v[0]:\n",
        "        return [str(d[\"answer\"]) for d in v if \"answer\" in d]\n",
        "\n",
        "    if isinstance(v, (list, tuple)):\n",
        "        return [str(x) for x in v]\n",
        "\n",
        "    if np is not None and isinstance(v, np.ndarray):\n",
        "        if v.shape == ():\n",
        "            return [str(v.item())]\n",
        "        return [str(x) for x in v.tolist()]\n",
        "\n",
        "    return [str(v)]\n",
        "\n",
        "def _get_question_list(ex: Dict[str, Any]) -> List[str]:\n",
        "    raw = _first_present(ex, [\"question\", \"question_text\", \"prompt\", \"Q\"])\n",
        "    return _to_list_of_str(raw)\n",
        "\n",
        "def _get_answer_list(ex: Dict[str, Any]) -> List[str]:\n",
        "    raw = _first_present(ex, [\"answers\", \"answer\", \"label\", \"A\"])\n",
        "    return _to_list_of_str(raw)\n",
        "\n",
        "def _get_image_obj(ex: Dict[str, Any]) -> Any:\n",
        "    return (\n",
        "        ex.get(\"image\")\n",
        "        or ex.get(\"image_path\")\n",
        "        or ex.get(\"image_url\")\n",
        "        or ex.get(\"img\")\n",
        "        or ex.get(\"filepath\")\n",
        "        or ex.get(\"file\")\n",
        "        or ex.get(\"path\")\n",
        "    )\n",
        "\n",
        "# -------------------------\n",
        "# Image â†’ local path\n",
        "# -------------------------\n",
        "def _save_pil_to_tmp(img: Image.Image, suffix=\".jpg\") -> str:\n",
        "    fp = tempfile.NamedTemporaryFile(delete=False, suffix=suffix).name\n",
        "    img.save(fp, \"JPEG\" if suffix.lower() in (\".jpg\", \".jpeg\") else \"PNG\")\n",
        "    return fp\n",
        "\n",
        "def _to_local_path(obj: Any) -> Optional[str]:\n",
        "    # PIL.Image.Image\n",
        "    if isinstance(obj, Image.Image):\n",
        "        return _save_pil_to_tmp(obj, \".jpg\")\n",
        "\n",
        "    # dict with bytes/path/url\n",
        "    if isinstance(obj, dict):\n",
        "        if \"bytes\" in obj:\n",
        "            try:\n",
        "                im = Image.open(io.BytesIO(obj[\"bytes\"]))\n",
        "                return _save_pil_to_tmp(im, \".jpg\")\n",
        "            except Exception:\n",
        "                pass\n",
        "        if \"path\" in obj:\n",
        "            return obj[\"path\"]\n",
        "        if \"url\" in obj:\n",
        "            obj = obj[\"url\"]  # fall through to str\n",
        "\n",
        "    # str: URL or filesystem\n",
        "    if isinstance(obj, str):\n",
        "        if obj.startswith((\"http://\", \"https://\")):\n",
        "            r = requests.get(obj, timeout=30)\n",
        "            r.raise_for_status()\n",
        "            suffix = pathlib.Path(obj).suffix or \".jpg\"\n",
        "            fp = tempfile.NamedTemporaryFile(delete=False, suffix=suffix).name\n",
        "            with open(fp, \"wb\") as f:\n",
        "                f.write(r.content)\n",
        "            return fp\n",
        "        return obj  # assume local path\n",
        "\n",
        "    # array-like â†’ try PIL\n",
        "    try:\n",
        "        im = Image.fromarray(obj)  # type: ignore[arg-type]\n",
        "        return _save_pil_to_tmp(im, \".jpg\")\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def _guess_mime(path: str) -> str:\n",
        "    mt, _ = mimetypes.guess_type(path)\n",
        "    return mt or \"image/jpeg\"\n",
        "\n",
        "# -------------------------\n",
        "# GCS upload\n",
        "# -------------------------\n",
        "storage_client = storage.Client(project=PROJECT_ID)\n",
        "_bucket = storage_client.bucket(GCS_BUCKET)\n",
        "\n",
        "def _upload(local_path: str, dst_key: str) -> str:\n",
        "    blob = _bucket.blob(dst_key)\n",
        "    blob.upload_from_filename(local_path)\n",
        "    return f\"gs://{GCS_BUCKET}/{dst_key}\"\n",
        "\n",
        "# -------------------------\n",
        "# Collect rows for a split (fans out multi-Q/A)\n",
        "# -------------------------\n",
        "def _collect_for_split(split_name: str, max_n: int) -> List[Tuple[str, str, str, str]]:\n",
        "    \"\"\"\n",
        "    Returns list of (question, answer, gs://image_uri, mime) for the split.\n",
        "    If a sample has multiple Q/A (lists/ndarrays), emit one row per pair,\n",
        "    reusing the same uploaded image URI.\n",
        "    \"\"\"\n",
        "    raw = _get_raw_split(split_name)\n",
        "    total = _row_count(raw)\n",
        "    want = min(max_n, total if total is not None else max_n)\n",
        "    rows: List[Tuple[str, str, str, str]] = []\n",
        "\n",
        "    for i in tqdm(range(total), desc=f\"Collect {split_name}\"):\n",
        "        if len(rows) >= want:\n",
        "            break\n",
        "        ex = _get_row(raw, i)\n",
        "\n",
        "        img_obj = _get_image_obj(ex)\n",
        "        if not img_obj:\n",
        "            continue\n",
        "\n",
        "        lp = _to_local_path(img_obj)\n",
        "        if not lp or not pathlib.Path(lp).exists():\n",
        "            continue\n",
        "\n",
        "        mime = _guess_mime(lp)\n",
        "        dst_key = f\"{GCS_PREFIX}/{SELECTED_HF_NAME}/{split_name}/images/{i}{pathlib.Path(lp).suffix}\"\n",
        "        uri = _upload(lp, dst_key)\n",
        "\n",
        "        qs = _get_question_list(ex)\n",
        "        ans = _get_answer_list(ex)\n",
        "\n",
        "        if not qs and not ans:\n",
        "            qs = [\"Answer the question about the image.\"]\n",
        "            ans = [\"\"]\n",
        "\n",
        "        # Pair questions and answers sensibly\n",
        "        if len(qs) > 1 and len(ans) > 1:\n",
        "            k = min(len(qs), len(ans))\n",
        "            pairs = zip(qs[:k], ans[:k])\n",
        "        elif len(qs) > 1 and len(ans) == 1:\n",
        "            pairs = ((q, ans[0]) for q in qs)\n",
        "        elif len(qs) == 1 and len(ans) > 1:\n",
        "            pairs = ((qs[0], a) for a in ans)\n",
        "        else:\n",
        "            pairs = ((qs[0] if qs else \"\", ans[0] if ans else \"\"),)\n",
        "\n",
        "        for q, a in pairs:\n",
        "            rows.append((q, a, uri, mime))\n",
        "            if len(rows) >= want:\n",
        "                break\n",
        "\n",
        "    return rows\n",
        "\n",
        "# -------------------------\n",
        "# Build & upload JSONL\n",
        "# -------------------------\n",
        "def _write_gemini_jsonl(rows: List[Tuple[str, str, str, str]], out_path: str):\n",
        "    \"\"\"\n",
        "    Each line:\n",
        "    {\"contents\":[\n",
        "       {\"role\":\"user\",\"parts\":[{\"fileData\":{\"mimeType\": \"...\",\"fileUri\":\"gs://...\"}},{\"text\":\"question\"}]},\n",
        "       {\"role\":\"model\",\"parts\":[{\"text\":\"answer\"}]}\n",
        "    ]}\n",
        "    \"\"\"\n",
        "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for q, a, uri, mime in rows:\n",
        "            record = {\n",
        "                \"contents\": [\n",
        "                    {\"role\": \"user\", \"parts\": [\n",
        "                        {\"fileData\": {\"mimeType\": mime, \"fileUri\": uri}},\n",
        "                        {\"text\": q or \"Answer the question about the image.\"}\n",
        "                    ]},\n",
        "                    {\"role\": \"model\", \"parts\": [{\"text\": str(a)}]}\n",
        "                ]\n",
        "            }\n",
        "            f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "# -------------------------\n",
        "# Run collection, write, and upload\n",
        "# -------------------------\n",
        "train_rows = _collect_for_split(TRAIN_SPLIT, MAX_TRAIN_EXAMPLES)\n",
        "val_rows   = _collect_for_split(VAL_SPLIT,   MAX_VAL_EXAMPLES)\n",
        "\n",
        "print(f\"âœ… Prepared {len(train_rows)} train / {len(val_rows)} val examples (uploaded images to GCS).\")\n",
        "\n",
        "train_jsonl_local = \"/content/sft_train.jsonl\"\n",
        "val_jsonl_local   = \"/content/sft_validation.jsonl\"\n",
        "_ = _write_gemini_jsonl(train_rows, train_jsonl_local)\n",
        "_ = _write_gemini_jsonl(val_rows,   val_jsonl_local)\n",
        "print(\"ðŸ“„ Wrote:\", train_jsonl_local, \"and\", val_jsonl_local)\n",
        "\n",
        "def gs_uri(*parts):\n",
        "    return \"gs://\" + \"/\".join([GCS_BUCKET] + [p.strip(\"/\") for p in parts])\n",
        "\n",
        "# Keep directory names aligned with actual split names\n",
        "train_jsonl_gcs = gs_uri(GCS_PREFIX, SELECTED_HF_NAME, TRAIN_SPLIT, \"sft_train.jsonl\")\n",
        "val_jsonl_gcs   = gs_uri(GCS_PREFIX, SELECTED_HF_NAME, VAL_SPLIT,   \"sft_validation.jsonl\")\n",
        "\n",
        "_bucket.blob(train_jsonl_gcs.replace(f\"gs://{GCS_BUCKET}/\",\"\")).upload_from_filename(train_jsonl_local)\n",
        "_bucket.blob(val_jsonl_gcs.replace(f\"gs://{GCS_BUCKET}/\",\"\")).upload_from_filename(val_jsonl_local)\n",
        "\n",
        "print(\"ðŸŸ¢ Training JSONL:\", train_jsonl_gcs)\n",
        "print(\"ðŸŸ¢ Validation JSONL:\", val_jsonl_gcs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETwAHuOi-q1Q",
        "outputId": "9333a100-f8f7-43c1-9020-fc2c66bc8570"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected HF dataset: dataset\n",
            "Splits: train='train'  val='validation'  (available: ['train', 'validation', 'test'])\n",
            "Caps: MAX_TRAIN_EXAMPLES=15  MAX_VAL_EXAMPLES=10\n",
            "GCS: gs://my-gemini-sft-bucket-group-6/multimodal_sft_20251130_040559/...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Collect train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:22<00:00,  1.47s/it]\n",
            "Collect validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:12<00:00,  1.21s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Prepared 15 train / 10 val examples (uploaded images to GCS).\n",
            "ðŸ“„ Wrote: /content/sft_train.jsonl and /content/sft_validation.jsonl\n",
            "ðŸŸ¢ Training JSONL: gs://my-gemini-sft-bucket-group-6/multimodal_sft_20251130_040559/dataset/train/sft_train.jsonl\n",
            "ðŸŸ¢ Validation JSONL: gs://my-gemini-sft-bucket-group-6/multimodal_sft_20251130_040559/dataset/validation/sft_validation.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 6: Start the Gemini supervised fine-tuning job"
      ],
      "metadata": {
        "id": "InfbqKoEaU3O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 6 â€” Start the Gemini supervised fine-tuning job (handles SDK arg name changes)\n",
        "from vertexai.tuning import sft\n",
        "\n",
        "BASE_MODEL_ = BASE_MODEL\n",
        "EPOCHS_     = int(EPOCHS)\n",
        "LRM_        = float(LEARNING_RATE_MULTIPLIER)\n",
        "ADAPTER_    = ADAPTER_SIZE_NUM\n",
        "\n",
        "\n",
        "print(\"Adapter size is \", ADAPTER_SIZE_NUM)\n",
        "\n",
        "def launch_sft():\n",
        "    # Weâ€™ll try several argument name variants to handle SDK differences.\n",
        "    base = {\n",
        "        \"source_model\": BASE_MODEL_,\n",
        "        \"train_dataset\": train_jsonl_gcs,\n",
        "        \"adapter_size\": ADAPTER_,\n",
        "    }\n",
        "    # possible variants by SDK version:\n",
        "    epoch_keys = [\"epochs\", \"epoch_count\", \"num_epochs\"]\n",
        "    val_keys   = [\"validation_dataset\", \"eval_dataset\", \"validation_data\", None]\n",
        "    lr_keys    = [\"learning_rate_multiplier\", \"learning_rate\", None]\n",
        "\n",
        "    last_err = None\n",
        "    for ek in epoch_keys:\n",
        "        for vk in val_keys:\n",
        "            for lk in lr_keys:\n",
        "                kwargs = base.copy()\n",
        "                kwargs[ek] = EPOCHS_\n",
        "                if vk: kwargs[vk] = val_jsonl_gcs\n",
        "                if lk: kwargs[lk] = LRM_\n",
        "                try:\n",
        "                    print(f\"Trying signature: {ek} / {vk or '(no-val-key)'} / {lk or '(no-lr-key)'}\")\n",
        "                    job = sft.train(**kwargs)\n",
        "                    print(f\"âœ… Launched with ({ek}, {vk or 'â€”'}, {lk or 'â€”'})\")\n",
        "                    return job\n",
        "                except TypeError as e:\n",
        "                    # wrong signature for this SDK version â€” try next combo\n",
        "                    last_err = e\n",
        "                except Exception as e:\n",
        "                    # real runtime error (e.g., bad dataset URI) â€” surface immediately\n",
        "                    raise\n",
        "    raise TypeError(f\"Could not find a working sft.train signature for this SDK.\\nLast error: {last_err}\")\n",
        "\n",
        "tuning_job = launch_sft()\n",
        "\n",
        "print(\"ðŸš€ Launched tuning job:\")\n",
        "print(\"   name:\", tuning_job.name)  # projects/.../locations/.../tuningJobs/...\n",
        "# If you still have `tuning_job` in memory, this will work:\n",
        "job_id_or_name = tuning_job.name if 'tuning_job' in globals() else \"3450221531811020800\"  # â† paste ID if needed\n",
        "globals()['job_id_or_name'] = job_id_or_name  # now available to later"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "xGVmc4FLukeo",
        "outputId": "75c8cd60-fff8-4b19-8bf0-02be428c063d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:vertexai.tuning._tuning:Creating SupervisedTuningJob\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adapter size is  4\n",
            "Trying signature: epochs / validation_dataset / learning_rate_multiplier\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:vertexai.tuning._tuning:SupervisedTuningJob created. Resource name: projects/939190881999/locations/us-central1/tuningJobs/5691505994245341184\n",
            "INFO:vertexai.tuning._tuning:To use this SupervisedTuningJob in another session:\n",
            "INFO:vertexai.tuning._tuning:tuning_job = sft.SupervisedTuningJob('projects/939190881999/locations/us-central1/tuningJobs/5691505994245341184')\n",
            "INFO:vertexai.tuning._tuning:View Tuning Job:\n",
            "https://console.cloud.google.com/vertex-ai/generative/language/locations/us-central1/tuning/tuningJob/5691505994245341184?project=939190881999\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        \n",
              "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
              "    <style>\n",
              "      .view-vertex-resource,\n",
              "      .view-vertex-resource:hover,\n",
              "      .view-vertex-resource:visited {\n",
              "        position: relative;\n",
              "        display: inline-flex;\n",
              "        flex-direction: row;\n",
              "        height: 32px;\n",
              "        padding: 0 12px;\n",
              "          margin: 4px 18px;\n",
              "        gap: 4px;\n",
              "        border-radius: 4px;\n",
              "\n",
              "        align-items: center;\n",
              "        justify-content: center;\n",
              "        background-color: rgb(255, 255, 255);\n",
              "        color: rgb(51, 103, 214);\n",
              "\n",
              "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
              "        font-size: 13px;\n",
              "        font-weight: 500;\n",
              "        text-transform: uppercase;\n",
              "        text-decoration: none !important;\n",
              "\n",
              "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
              "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active {\n",
              "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
              "        position: absolute;\n",
              "        top: 0;\n",
              "        bottom: 0;\n",
              "        left: 0;\n",
              "        right: 0;\n",
              "        border-radius: 4px;\n",
              "        pointer-events: none;\n",
              "\n",
              "        content: '';\n",
              "        background-color: rgb(51, 103, 214);\n",
              "        opacity: 0.12;\n",
              "      }\n",
              "      .view-vertex-icon {\n",
              "        font-size: 18px;\n",
              "      }\n",
              "    </style>\n",
              "  \n",
              "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-312d164a-9475-4030-80e6-684cf4779616\" href=\"#view-view-vertex-resource-312d164a-9475-4030-80e6-684cf4779616\">\n",
              "          <span class=\"material-icons view-vertex-icon\">tune</span>\n",
              "          <span>View Tuning Job</span>\n",
              "        </a>\n",
              "        \n",
              "        <script>\n",
              "          (function () {\n",
              "            const link = document.getElementById('view-vertex-resource-312d164a-9475-4030-80e6-684cf4779616');\n",
              "            link.addEventListener('click', (e) => {\n",
              "              if (window.google?.colab?.openUrl) {\n",
              "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/generative/language/locations/us-central1/tuning/tuningJob/5691505994245341184?project=939190881999');\n",
              "              } else {\n",
              "                window.open('https://console.cloud.google.com/vertex-ai/generative/language/locations/us-central1/tuning/tuningJob/5691505994245341184?project=939190881999', '_blank');\n",
              "              }\n",
              "              e.stopPropagation();\n",
              "              e.preventDefault();\n",
              "            });\n",
              "          })();\n",
              "        </script>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Launched with (epochs, validation_dataset, learning_rate_multiplier)\n",
            "ðŸš€ Launched tuning job:\n",
            "   name: 5691505994245341184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "globals()['job_id_or_name'] = \"\"  # now available to later"
      ],
      "metadata": {
        "id": "HJFAxR14SU23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 6.1 State status of training\n",
        "\n",
        "In Vertex AI (the service backing Gemini fine-tuning), the state field is an enum.\n",
        "\n",
        "For SupervisedTuningJob the values map like this:\n",
        "\n",
        "1 â†’ STATE_UNSPECIFIED (default / not set)\n",
        "\n",
        "2 â†’ PENDING (job created, not yet running)\n",
        "\n",
        "3 â†’ RUNNING ðŸš€ (your training job is actively running right now)\n",
        "\n",
        "4 â†’ SUCCEEDED (finished successfully)\n",
        "\n",
        "5 â†’ FAILED\n",
        "\n",
        "6 â†’ CANCELLING\n",
        "\n",
        "7 â†’ CANCELLED"
      ],
      "metadata": {
        "id": "FtMr9Qe1D6tU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 6.1 â€” Inspect a specific tuning job (status, tuned endpoint)\n",
        "from vertexai.tuning import sft\n",
        "\n",
        "\n",
        "def _full_job_name(j):\n",
        "    # Accept either just the numeric ID or the full resource name\n",
        "    if \"/\" in j:\n",
        "        return j\n",
        "    return f\"projects/{PROJECT_ID}/locations/{REGION}/tuningJobs/{j}\"\n",
        "\n",
        "name = _full_job_name(job_id_or_name)\n",
        "job = sft.SupervisedTuningJob(name).refresh()\n",
        "\n",
        "print(\"Job name:   \", job.name)\n",
        "print(\"State:      \", job.state)\n",
        "print(\"Create time:\", getattr(job, \"create_time\", None))\n",
        "print(\"Start time: \", getattr(job, \"start_time\", None))\n",
        "print(\"End time:   \", getattr(job, \"end_time\", None))\n",
        "\n",
        "# If finished, a tuned model reference is usually attached:\n",
        "tm = getattr(job, \"tuned_model\", None)\n",
        "if tm:\n",
        "    print(\"Tuned model:\", tm)\n",
        "    # Some SDK versions expose an endpoint under tuned_model.endpoint\n",
        "    if hasattr(tm, \"endpoint\"):\n",
        "        print(\"Endpoint:   \", tm.endpoint)\n",
        "else:\n",
        "    print(\"Tuned model: (not available yet â€” job is still running)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "Yk2Ct1yyxVqW",
        "outputId": "5d5e960a-ef7e-4f38-bdd6-462116a579cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        \n",
              "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
              "    <style>\n",
              "      .view-vertex-resource,\n",
              "      .view-vertex-resource:hover,\n",
              "      .view-vertex-resource:visited {\n",
              "        position: relative;\n",
              "        display: inline-flex;\n",
              "        flex-direction: row;\n",
              "        height: 32px;\n",
              "        padding: 0 12px;\n",
              "          margin: 4px 18px;\n",
              "        gap: 4px;\n",
              "        border-radius: 4px;\n",
              "\n",
              "        align-items: center;\n",
              "        justify-content: center;\n",
              "        background-color: rgb(255, 255, 255);\n",
              "        color: rgb(51, 103, 214);\n",
              "\n",
              "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
              "        font-size: 13px;\n",
              "        font-weight: 500;\n",
              "        text-transform: uppercase;\n",
              "        text-decoration: none !important;\n",
              "\n",
              "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
              "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active {\n",
              "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
              "        position: absolute;\n",
              "        top: 0;\n",
              "        bottom: 0;\n",
              "        left: 0;\n",
              "        right: 0;\n",
              "        border-radius: 4px;\n",
              "        pointer-events: none;\n",
              "\n",
              "        content: '';\n",
              "        background-color: rgb(51, 103, 214);\n",
              "        opacity: 0.12;\n",
              "      }\n",
              "      .view-vertex-icon {\n",
              "        font-size: 18px;\n",
              "      }\n",
              "    </style>\n",
              "  \n",
              "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-af567a81-2862-4b7b-a37f-c829d26dc88e\" href=\"#view-view-vertex-resource-af567a81-2862-4b7b-a37f-c829d26dc88e\">\n",
              "          <span class=\"material-icons view-vertex-icon\">tune</span>\n",
              "          <span>View Tuning Job</span>\n",
              "        </a>\n",
              "        \n",
              "        <script>\n",
              "          (function () {\n",
              "            const link = document.getElementById('view-vertex-resource-af567a81-2862-4b7b-a37f-c829d26dc88e');\n",
              "            link.addEventListener('click', (e) => {\n",
              "              if (window.google?.colab?.openUrl) {\n",
              "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/generative/language/locations/us-central1/tuning/tuningJob/5691505994245341184?project=939190881999');\n",
              "              } else {\n",
              "                window.open('https://console.cloud.google.com/vertex-ai/generative/language/locations/us-central1/tuning/tuningJob/5691505994245341184?project=939190881999', '_blank');\n",
              "              }\n",
              "              e.stopPropagation();\n",
              "              e.preventDefault();\n",
              "            });\n",
              "          })();\n",
              "        </script>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        \n",
              "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
              "    <style>\n",
              "      .view-vertex-resource,\n",
              "      .view-vertex-resource:hover,\n",
              "      .view-vertex-resource:visited {\n",
              "        position: relative;\n",
              "        display: inline-flex;\n",
              "        flex-direction: row;\n",
              "        height: 32px;\n",
              "        padding: 0 12px;\n",
              "          margin: 4px 18px;\n",
              "        gap: 4px;\n",
              "        border-radius: 4px;\n",
              "\n",
              "        align-items: center;\n",
              "        justify-content: center;\n",
              "        background-color: rgb(255, 255, 255);\n",
              "        color: rgb(51, 103, 214);\n",
              "\n",
              "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
              "        font-size: 13px;\n",
              "        font-weight: 500;\n",
              "        text-transform: uppercase;\n",
              "        text-decoration: none !important;\n",
              "\n",
              "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
              "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active {\n",
              "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
              "        position: absolute;\n",
              "        top: 0;\n",
              "        bottom: 0;\n",
              "        left: 0;\n",
              "        right: 0;\n",
              "        border-radius: 4px;\n",
              "        pointer-events: none;\n",
              "\n",
              "        content: '';\n",
              "        background-color: rgb(51, 103, 214);\n",
              "        opacity: 0.12;\n",
              "      }\n",
              "      .view-vertex-icon {\n",
              "        font-size: 18px;\n",
              "      }\n",
              "    </style>\n",
              "  \n",
              "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-814f9e10-3a5d-4146-81d7-774893041539\" href=\"#view-view-vertex-resource-814f9e10-3a5d-4146-81d7-774893041539\">\n",
              "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
              "          <span>View Experiment</span>\n",
              "        </a>\n",
              "        \n",
              "        <script>\n",
              "          (function () {\n",
              "            const link = document.getElementById('view-vertex-resource-814f9e10-3a5d-4146-81d7-774893041539');\n",
              "            link.addEventListener('click', (e) => {\n",
              "              if (window.google?.colab?.openUrl) {\n",
              "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/tuning-experiment-20251129200855458690/runs?project=project-2-group-6');\n",
              "              } else {\n",
              "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/tuning-experiment-20251129200855458690/runs?project=project-2-group-6', '_blank');\n",
              "              }\n",
              "              e.stopPropagation();\n",
              "              e.preventDefault();\n",
              "            });\n",
              "          })();\n",
              "        </script>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Job name:    5691505994245341184\n",
            "State:       4\n",
            "Create time: 2025-11-30 04:08:32.651800+00:00\n",
            "Start time:  None\n",
            "End time:    None\n",
            "Tuned model: (not available yet â€” job is still running)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 7 : Inspect job & list all jobs"
      ],
      "metadata": {
        "id": "FgTe24Suy7nS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 7 â€” Inspect this tuning job & list all jobs\n",
        "from vertexai.tuning import sft\n",
        "\n",
        "assert 'job_id_or_name' in globals(), \"Run STEP 6 first to set job_id_or_name.\"\n",
        "\n",
        "def _full_job_name(j):\n",
        "    return j if \"/\" in j else f\"projects/{PROJECT_ID}/locations/{REGION}/tuningJobs/{j}\"\n",
        "\n",
        "name = _full_job_name(job_id_or_name)\n",
        "job  = sft.SupervisedTuningJob(name).refresh()\n",
        "\n",
        "print(\"Job:\", job.name)\n",
        "print(\"State:\", job.state)\n",
        "print(\"Create:\", getattr(job, \"create_time\", None))\n",
        "print(\"Start :\", getattr(job, \"start_time\", None))\n",
        "print(\"End   :\", getattr(job, \"end_time\", None))\n",
        "tm = getattr(job, \"tuned_model\", None)\n",
        "print(\"Tuned model:\", tm if tm else \"(not ready yet)\")\n",
        "\n",
        "print(\"\\nAll jobs in project/region:\")\n",
        "for j in sft.SupervisedTuningJob.list():\n",
        "    print(\" â€¢\", j.name, \"â†’\", j.state, getattr(j, \"tuned_model\", None))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "H-o6lnuqy9e-",
        "outputId": "257765bd-e40d-4d5f-b960-5f0c94bcf591"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        \n",
              "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
              "    <style>\n",
              "      .view-vertex-resource,\n",
              "      .view-vertex-resource:hover,\n",
              "      .view-vertex-resource:visited {\n",
              "        position: relative;\n",
              "        display: inline-flex;\n",
              "        flex-direction: row;\n",
              "        height: 32px;\n",
              "        padding: 0 12px;\n",
              "          margin: 4px 18px;\n",
              "        gap: 4px;\n",
              "        border-radius: 4px;\n",
              "\n",
              "        align-items: center;\n",
              "        justify-content: center;\n",
              "        background-color: rgb(255, 255, 255);\n",
              "        color: rgb(51, 103, 214);\n",
              "\n",
              "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
              "        font-size: 13px;\n",
              "        font-weight: 500;\n",
              "        text-transform: uppercase;\n",
              "        text-decoration: none !important;\n",
              "\n",
              "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
              "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active {\n",
              "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
              "        position: absolute;\n",
              "        top: 0;\n",
              "        bottom: 0;\n",
              "        left: 0;\n",
              "        right: 0;\n",
              "        border-radius: 4px;\n",
              "        pointer-events: none;\n",
              "\n",
              "        content: '';\n",
              "        background-color: rgb(51, 103, 214);\n",
              "        opacity: 0.12;\n",
              "      }\n",
              "      .view-vertex-icon {\n",
              "        font-size: 18px;\n",
              "      }\n",
              "    </style>\n",
              "  \n",
              "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-634ad61c-11ee-4cf6-b6df-8a76a4dc825e\" href=\"#view-view-vertex-resource-634ad61c-11ee-4cf6-b6df-8a76a4dc825e\">\n",
              "          <span class=\"material-icons view-vertex-icon\">tune</span>\n",
              "          <span>View Tuning Job</span>\n",
              "        </a>\n",
              "        \n",
              "        <script>\n",
              "          (function () {\n",
              "            const link = document.getElementById('view-vertex-resource-634ad61c-11ee-4cf6-b6df-8a76a4dc825e');\n",
              "            link.addEventListener('click', (e) => {\n",
              "              if (window.google?.colab?.openUrl) {\n",
              "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/generative/language/locations/us-central1/tuning/tuningJob/5691505994245341184?project=939190881999');\n",
              "              } else {\n",
              "                window.open('https://console.cloud.google.com/vertex-ai/generative/language/locations/us-central1/tuning/tuningJob/5691505994245341184?project=939190881999', '_blank');\n",
              "              }\n",
              "              e.stopPropagation();\n",
              "              e.preventDefault();\n",
              "            });\n",
              "          })();\n",
              "        </script>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        \n",
              "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
              "    <style>\n",
              "      .view-vertex-resource,\n",
              "      .view-vertex-resource:hover,\n",
              "      .view-vertex-resource:visited {\n",
              "        position: relative;\n",
              "        display: inline-flex;\n",
              "        flex-direction: row;\n",
              "        height: 32px;\n",
              "        padding: 0 12px;\n",
              "          margin: 4px 18px;\n",
              "        gap: 4px;\n",
              "        border-radius: 4px;\n",
              "\n",
              "        align-items: center;\n",
              "        justify-content: center;\n",
              "        background-color: rgb(255, 255, 255);\n",
              "        color: rgb(51, 103, 214);\n",
              "\n",
              "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
              "        font-size: 13px;\n",
              "        font-weight: 500;\n",
              "        text-transform: uppercase;\n",
              "        text-decoration: none !important;\n",
              "\n",
              "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
              "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active {\n",
              "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
              "        position: absolute;\n",
              "        top: 0;\n",
              "        bottom: 0;\n",
              "        left: 0;\n",
              "        right: 0;\n",
              "        border-radius: 4px;\n",
              "        pointer-events: none;\n",
              "\n",
              "        content: '';\n",
              "        background-color: rgb(51, 103, 214);\n",
              "        opacity: 0.12;\n",
              "      }\n",
              "      .view-vertex-icon {\n",
              "        font-size: 18px;\n",
              "      }\n",
              "    </style>\n",
              "  \n",
              "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-66962ba4-144a-4e2b-a518-b37b4997d124\" href=\"#view-view-vertex-resource-66962ba4-144a-4e2b-a518-b37b4997d124\">\n",
              "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
              "          <span>View Experiment</span>\n",
              "        </a>\n",
              "        \n",
              "        <script>\n",
              "          (function () {\n",
              "            const link = document.getElementById('view-vertex-resource-66962ba4-144a-4e2b-a518-b37b4997d124');\n",
              "            link.addEventListener('click', (e) => {\n",
              "              if (window.google?.colab?.openUrl) {\n",
              "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/tuning-experiment-20251129200855458690/runs?project=project-2-group-6');\n",
              "              } else {\n",
              "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/tuning-experiment-20251129200855458690/runs?project=project-2-group-6', '_blank');\n",
              "              }\n",
              "              e.stopPropagation();\n",
              "              e.preventDefault();\n",
              "            });\n",
              "          })();\n",
              "        </script>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Job: 5691505994245341184\n",
            "State: 3\n",
            "Create: 2025-11-30 04:08:32.651800+00:00\n",
            "Start : None\n",
            "End   : None\n",
            "Tuned model: (not ready yet)\n",
            "\n",
            "All jobs in project/region:\n",
            " â€¢ 5691505994245341184 â†’ 3 None\n",
            " â€¢ 7582676336301309952 â†’ 4 None\n",
            " â€¢ 22912671271616512 â†’ 4 None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 8: Fetch tuned endpoint & try a few predictions"
      ],
      "metadata": {
        "id": "ge47VX0tzMoC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 8 â€” Fetch tuned endpoint (Vertex AI client) and test + DISPLAY IMAGES\n",
        "from google import genai\n",
        "from google.genai.types import HttpOptions\n",
        "from vertexai.tuning import sft\n",
        "from google.cloud import storage\n",
        "from IPython.display import display\n",
        "from PIL import Image\n",
        "import io, requests, re, pathlib\n",
        "\n",
        "assert 'job_id_or_name' in globals(), \"Run STEP 6 first.\"\n",
        "\n",
        "# Build full job name if user only saved the numeric ID\n",
        "name = job_id_or_name if \"/\" in job_id_or_name else f\"projects/{PROJECT_ID}/locations/{REGION}/tuningJobs/{job_id_or_name}\"\n",
        "\n",
        "# âœ… Init the Google GenAI client for **Vertex AI** (Cloud)\n",
        "client = genai.Client(\n",
        "    vertexai=True,\n",
        "    project=PROJECT_ID,\n",
        "    location=REGION,\n",
        "    http_options=HttpOptions(api_version=\"v1\"),\n",
        ")\n",
        "\n",
        "# Get tuned endpoint (SDK first, then Tunings API)\n",
        "job = sft.SupervisedTuningJob(name).refresh()\n",
        "print(\"Job state:\", job.state)\n",
        "\n",
        "endpoint = None\n",
        "tm = getattr(job, \"tuned_model\", None)\n",
        "if tm and getattr(tm, \"endpoint\", None):\n",
        "    endpoint = tm.endpoint\n",
        "if endpoint is None:\n",
        "    tuned = client.tunings.get(name=name)\n",
        "    if getattr(tuned, \"tuned_model\", None):\n",
        "        endpoint = tuned.tuned_model.endpoint\n",
        "\n",
        "if not endpoint:\n",
        "    raise RuntimeError(\"Tuned endpoint not available yet. Confirm the job has SUCCEEDED (see STEP 7/7.1 or Console).\")\n",
        "\n",
        "print(\"ðŸŸ¢ Tuned endpoint:\", endpoint)\n",
        "globals()['endpoint'] = endpoint  # expose for later steps\n",
        "\n",
        "# ---------- helpers to load & display images ----------\n",
        "_storage = storage.Client(project=PROJECT_ID)\n",
        "\n",
        "def _load_image(uri_or_path):\n",
        "    \"\"\"Return a PIL.Image from gs://, http(s)://, or local path.\"\"\"\n",
        "    if isinstance(uri_or_path, str) and uri_or_path.startswith(\"gs://\"):\n",
        "        # gs://bucket/key\n",
        "        m = re.match(r\"gs://([^/]+)/(.+)\", uri_or_path)\n",
        "        if not m:\n",
        "            return None\n",
        "        bkt, key = m.group(1), m.group(2)\n",
        "        blob = _storage.bucket(bkt).blob(key)\n",
        "        data = blob.download_as_bytes()\n",
        "        return Image.open(io.BytesIO(data)).convert(\"RGB\")\n",
        "    if isinstance(uri_or_path, str) and uri_or_path.startswith((\"http://\",\"https://\")):\n",
        "        r = requests.get(uri_or_path, timeout=30)\n",
        "        r.raise_for_status()\n",
        "        return Image.open(io.BytesIO(r.content)).convert(\"RGB\")\n",
        "    # local file path (rare in this flow)\n",
        "    p = pathlib.Path(str(uri_or_path))\n",
        "    if p.exists():\n",
        "        return Image.open(p).convert(\"RGB\")\n",
        "    return None\n",
        "\n",
        "def _safe_text(resp):\n",
        "    try:\n",
        "        return (resp.text or \"\").strip()\n",
        "    except Exception:\n",
        "        parts = getattr(resp, \"candidates\", []) or []\n",
        "        for c in parts:\n",
        "            content = getattr(c, \"content\", None)\n",
        "            if content:\n",
        "                for part in getattr(content, \"parts\", []) or []:\n",
        "                    if isinstance(part, dict) and \"text\" in part:\n",
        "                        return part[\"text\"].strip()\n",
        "        return \"\"\n",
        "\n",
        "# ---- Test a few validation examples & DISPLAY the image ----\n",
        "assert 'val_rows' in globals() and len(val_rows), \"Run STEP 5 to prepare val_rows.\"\n",
        "NUM_PREVIEW = 5  # change if you want more/less\n",
        "preview = val_rows[:min(NUM_PREVIEW, len(val_rows))]\n",
        "\n",
        "print(f\"Testing {len(preview)} validation samples (showing images)â€¦\")\n",
        "\n",
        "for i, (q, a, uri, mime) in enumerate(preview, start=1):\n",
        "    print(f\"\\n[{i}] Q:\", q)\n",
        "    img = _load_image(uri)\n",
        "    if img:\n",
        "        display(img)\n",
        "    else:\n",
        "        print(\"(Image preview unavailable)\")\n",
        "\n",
        "    prompt = [\n",
        "        {\"role\":\"user\",\"parts\":[\n",
        "            {\"file_data\": {\"file_uri\": uri, \"mime_type\": mime}},\n",
        "            {\"text\": q or \"Answer the question about the image.\"}\n",
        "        ]}\n",
        "    ]\n",
        "    resp = client.models.generate_content(model=endpoint, contents=prompt)\n",
        "    pred = _safe_text(resp)\n",
        "\n",
        "    print(\"GT:\", a)\n",
        "    print(\"Pred:\", pred)\n"
      ],
      "metadata": {
        "id": "2bPAUxOJ4VDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#STEP 9: Compare Fine-Tuned Model to Original Gemini"
      ],
      "metadata": {
        "id": "9H0rb-N1KW5i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### STEP 9.1 run predictions on test data for both fine-tuned & base Gemini model"
      ],
      "metadata": {
        "id": "Qe6IRjuPouyf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9.1 A) â€” Evaluate tuned Gemini vs base Gemini using SFT JSONL (reads GT from file)\n",
        "from typing import Any, Dict, List, Optional, Tuple\n",
        "import json, os\n",
        "from tqdm import tqdm\n",
        "from google.genai import errors as genai_errors\n",
        "\n",
        "# Reuse client/endpoint from STEP 8\n",
        "assert 'client' in globals(), \"Run STEP 8 first to create `client`.\"\n",
        "assert 'endpoint' in globals() and endpoint, \"Run STEP 8 first to resolve `endpoint`.\"\n",
        "\n",
        "# ---------- Resolve a valid base Gemini model (prefer Gemini 2.5 Flash) ----------\n",
        "def _probe_model_id(mid: str) -> bool:\n",
        "    \"\"\"Return True if this model id is available to this project/region.\"\"\"\n",
        "    try:\n",
        "        try:\n",
        "            client.models.get(mid)            # most SDKs accept positional\n",
        "        except TypeError:\n",
        "            client.models.get(model=mid)      # fallback signature\n",
        "        return True\n",
        "    except genai_errors.ClientError as e:\n",
        "        # 404 => not available; 403 => not permitted; 400 => bad id format\n",
        "        if getattr(e, \"status_code\", None) not in (404, 403, 400):\n",
        "            print(f\"Probe {mid} -> {getattr(e,'status_code',None)} {getattr(e,'message',e)}\")\n",
        "        return False\n",
        "\n",
        "def _resolve_base_gemini(prefer_25: bool = True) -> str:\n",
        "    candidates_25 = [\n",
        "        \"publishers/google/models/gemini-2.5-flash\",\n",
        "        \"publishers/google/models/gemini-2.5-flash-001\",\n",
        "        \"models/gemini-2.5-flash\",\n",
        "        \"models/gemini-2.5-flash-001\",\n",
        "    ]\n",
        "    candidates_15 = [\n",
        "        \"publishers/google/models/gemini-1.5-flash-001\",\n",
        "        \"publishers/google/models/gemini-1.5-pro-002\",\n",
        "        \"models/gemini-1.5-flash-001\",\n",
        "        \"models/gemini-1.5-pro-002\",\n",
        "    ]\n",
        "    pool = (candidates_25 if prefer_25 else []) + candidates_15\n",
        "    for mid in pool:\n",
        "        if _probe_model_id(mid):\n",
        "            print(\"âœ… Base model available:\", mid)\n",
        "            return mid\n",
        "    raise RuntimeError(\"No base Gemini model ID worked in this project/region.\")\n",
        "\n",
        "# Respect an existing selection; else honor user BASE_MODEL; else resolve automatically\n",
        "if 'BASE_MODEL_FOR_GENAI' not in globals() or not BASE_MODEL_FOR_GENAI:\n",
        "    user_base = globals().get(\"BASE_MODEL\", None)\n",
        "    if user_base:\n",
        "        candidate = user_base if user_base.startswith((\"models/\",\"publishers/\")) else f\"models/{user_base}\"\n",
        "        if _probe_model_id(candidate):\n",
        "            BASE_MODEL_FOR_GENAI = candidate\n",
        "            print(\"Base model    :\", BASE_MODEL_FOR_GENAI)\n",
        "        else:\n",
        "            print(f\"Provided BASE_MODEL '{candidate}' not available; resolving a valid oneâ€¦\")\n",
        "            BASE_MODEL_FOR_GENAI = _resolve_base_gemini(prefer_25=True)\n",
        "    else:\n",
        "        BASE_MODEL_FOR_GENAI = _resolve_base_gemini(prefer_25=True)\n",
        "\n",
        "print(\"Tuned endpoint:\", endpoint)\n",
        "print(\"Base model    :\", BASE_MODEL_FOR_GENAI)\n",
        "\n",
        "# ---------- Use the SFT validation file (contains question + ground-truth answer) ----------\n",
        "test_path = \"sft_validation.jsonl\"  # adjust path if needed\n",
        "assert os.path.exists(test_path), f\"Missing {test_path}\"\n",
        "\n",
        "# ---------- Helpers ----------\n",
        "def _guess_mime(uri: str) -> str:\n",
        "    u = (uri or \"\").lower()\n",
        "    if u.endswith(\".png\"):  return \"image/png\"\n",
        "    if u.endswith(\".webp\"): return \"image/webp\"\n",
        "    if u.endswith(\".gif\"):  return \"image/gif\"\n",
        "    if u.endswith(\".bmp\"):  return \"image/bmp\"\n",
        "    return \"image/jpeg\"\n",
        "\n",
        "def parse_sft_record(rec: Dict[str, Any]) -> Tuple[str, Optional[str], Optional[str], str]:\n",
        "    \"\"\"\n",
        "    Parse a Gemini SFT JSONL record like:\n",
        "      {\"contents\":[\n",
        "         {\"role\":\"user\",\"parts\":[{\"fileData\":{\"mimeType\":\"...\",\"fileUri\":\"gs://...\"}},{\"text\":\"question\"}]},\n",
        "         {\"role\":\"model\",\"parts\":[{\"text\":\"answer\"}]}\n",
        "      ]}\n",
        "    Returns: (question_text, image_uri, mime_type, ground_truth_answer)\n",
        "    \"\"\"\n",
        "    q_text, img_uri, mime_type, gt = \"\", None, None, \"\"\n",
        "    contents = rec.get(\"contents\", [])\n",
        "    for message in contents:\n",
        "        role = message.get(\"role\")\n",
        "        for part in (message.get(\"parts\") or []):\n",
        "            if isinstance(part, dict):\n",
        "                if role == \"user\" and \"text\" in part and not q_text:\n",
        "                    q_text = str(part[\"text\"])\n",
        "                fd = part.get(\"fileData\") or part.get(\"file_data\")\n",
        "                if role == \"user\" and isinstance(fd, dict):\n",
        "                    img_uri   = fd.get(\"fileUri\")  or fd.get(\"file_uri\")  or img_uri\n",
        "                    mime_type = fd.get(\"mimeType\") or fd.get(\"mime_type\") or mime_type\n",
        "                if role == \"model\" and \"text\" in part and not gt:\n",
        "                    gt = str(part[\"text\"])\n",
        "    return q_text.strip(), img_uri, mime_type, gt.strip()\n",
        "\n",
        "def parse_messages_record(rec: Dict[str, Any]) -> Tuple[str, Optional[str], Optional[str], str]:\n",
        "    # Fallback if you ever point test_path to an OpenAI-style messages file\n",
        "    msgs = rec.get(\"messages\", [])\n",
        "    user_msgs = [m for m in msgs if m.get(\"role\") == \"user\"]\n",
        "    last = user_msgs[-1] if user_msgs else (msgs[-1] if msgs else {})\n",
        "    txt = \"\"\n",
        "    img_uri, mime_type = None, None\n",
        "    content = last.get(\"content\", [])\n",
        "    if isinstance(content, dict): content = [content]\n",
        "    for c in content or []:\n",
        "        if c.get(\"type\") == \"text\" and \"text\" in c:\n",
        "            txt += c[\"text\"] if isinstance(c[\"text\"], str) else str(c[\"text\"])\n",
        "        if c.get(\"type\") in (\"input_image\", \"image_url\", \"input_image_url\", \"image\"):\n",
        "            if isinstance(c.get(\"image_url\"), dict):\n",
        "                img_uri = c[\"image_url\"].get(\"url\", img_uri)\n",
        "            elif isinstance(c.get(\"image_url\"), str):\n",
        "                img_uri = c[\"image_url\"]\n",
        "            elif \"url\" in c:\n",
        "                img_uri = c[\"url\"]\n",
        "    if not txt and isinstance(last.get(\"content\"), str):\n",
        "        txt = last[\"content\"]\n",
        "    mime_type = _guess_mime(img_uri) if img_uri and not mime_type else mime_type\n",
        "    return txt.strip(), img_uri, mime_type, \"\"\n",
        "\n",
        "def parse_record(rec: Dict[str, Any]) -> Tuple[str, Optional[str], Optional[str], str]:\n",
        "    return parse_sft_record(rec) if \"contents\" in rec else parse_messages_record(rec)\n",
        "\n",
        "def genai_predict(model_name: str, q_text: str, img_uri: Optional[str], mime_type: Optional[str]) -> str:\n",
        "    try:\n",
        "        parts = []\n",
        "        if img_uri:\n",
        "            parts.append({\"file_data\": {\"file_uri\": img_uri, \"mime_type\": mime_type or _guess_mime(img_uri)}})\n",
        "        parts.append({\"text\": q_text or \"Answer the question about the image.\"})\n",
        "        prompt = [{\"role\": \"user\", \"parts\": parts}]\n",
        "        resp = client.models.generate_content(model=model_name, contents=prompt)\n",
        "        txt = getattr(resp, \"text\", None)\n",
        "        if txt: return txt.strip()\n",
        "        cands = getattr(resp, \"candidates\", []) or []\n",
        "        if cands:\n",
        "            content = getattr(cands[0], \"content\", None)\n",
        "            if content and getattr(content, \"parts\", None):\n",
        "                first = content.parts[0]\n",
        "                if isinstance(first, dict) and \"text\" in first:\n",
        "                    return str(first[\"text\"]).strip()\n",
        "        return \"\"\n",
        "    except Exception as e:\n",
        "        return f\"[ERROR] {type(e).__name__}: {e}\"\n",
        "\n",
        "# ---------- Load tests ----------\n",
        "test_data: List[Dict[str, Any]] = []\n",
        "with open(test_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        test_data.append(json.loads(line))\n",
        "\n",
        "# ---------- Evaluate ----------\n",
        "def evaluate_model(model_name: str, out_path: str) -> int:\n",
        "    results = []\n",
        "    for idx, rec in tqdm(enumerate(test_data), total=len(test_data), desc=f\"Eval {os.path.basename(out_path)}\"):\n",
        "        q_text, img_uri, mime_type, gt = parse_record(rec)\n",
        "        pred = genai_predict(model_name, q_text, img_uri, mime_type)\n",
        "        results.append({\n",
        "            \"example_id\": idx,               # index in the file\n",
        "            \"predicted_answer\": pred,\n",
        "            \"actual_answer\": gt              # ground truth directly from file\n",
        "        })\n",
        "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for r in results:\n",
        "            f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n",
        "    return len(results)\n",
        "\n",
        "ft_out   = \"ocr-vqa-gemini-ft-results.jsonl\"\n",
        "base_out = \"ocr-vqa-gemini-base-results.jsonl\"\n",
        "\n",
        "n1 = evaluate_model(endpoint, ft_out)\n",
        "print(f\"âœ“ wrote {ft_out} ({n1} rows)\")\n",
        "n2 = evaluate_model(BASE_MODEL_FOR_GENAI, base_out)\n",
        "print(f\"âœ“ wrote {base_out} ({n2} rows)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbbgbcXOWiQa",
        "outputId": "8d914198-fa5f-4e4b-83e4-c3719bedbeae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probe models/gemini-2.5-flash -> None List of found errors:\t1.Field: name; Message: Invalid Model resource name.\t\n",
            "Provided BASE_MODEL 'models/gemini-2.5-flash' not available; resolving a valid oneâ€¦\n",
            "âœ… Base model available: publishers/google/models/gemini-2.5-flash\n",
            "Tuned endpoint: projects/939190881999/locations/us-central1/endpoints/4594470964871299072\n",
            "Base model    : publishers/google/models/gemini-2.5-flash\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Eval ocr-vqa-gemini-ft-results.jsonl: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:13<00:00, 13.32s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ wrote ocr-vqa-gemini-ft-results.jsonl (10 rows)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Eval ocr-vqa-gemini-base-results.jsonl: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:57<00:00, 11.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ wrote ocr-vqa-gemini-base-results.jsonl (10 rows)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9.1 B) â€” Preview first eval sample (image + Q/A + predictions)\n",
        "\n",
        "import os, json, io\n",
        "from IPython.display import display\n",
        "from PIL import Image as PILImage\n",
        "\n",
        "# Paths from Step 9.1 (change if you renamed them)\n",
        "test_path = \"sft_validation.jsonl\"\n",
        "ft_out    = \"ocr-vqa-gemini-ft-results.jsonl\"\n",
        "base_out  = \"ocr-vqa-gemini-base-results.jsonl\"\n",
        "\n",
        "def _guess_mime(uri: str) -> str:\n",
        "    u = (uri or \"\").lower()\n",
        "    if u.endswith(\".png\"):  return \"image/png\"\n",
        "    if u.endswith(\".webp\"): return \"image/webp\"\n",
        "    if u.endswith(\".gif\"):  return \"image/gif\"\n",
        "    if u.endswith(\".bmp\"):  return \"image/bmp\"\n",
        "    return \"image/jpeg\"\n",
        "\n",
        "def _parse_first_sft(path: str):\n",
        "    \"\"\"Return (question, image_uri, mime_type, ground_truth) for the first record.\"\"\"\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        line = f.readline()\n",
        "    rec = json.loads(line)\n",
        "\n",
        "    q_text, img_uri, mime_type, gt = \"\", None, None, \"\"\n",
        "    contents = rec.get(\"contents\", [])\n",
        "    for message in contents:\n",
        "        role = message.get(\"role\")\n",
        "        for part in (message.get(\"parts\") or []):\n",
        "            if isinstance(part, dict):\n",
        "                if role == \"user\" and \"text\" in part and not q_text:\n",
        "                    q_text = str(part[\"text\"])\n",
        "                fd = part.get(\"fileData\") or part.get(\"file_data\")\n",
        "                if role == \"user\" and isinstance(fd, dict) and not img_uri:\n",
        "                    img_uri   = fd.get(\"fileUri\")  or fd.get(\"file_uri\")\n",
        "                    mime_type = fd.get(\"mimeType\") or fd.get(\"mime_type\")\n",
        "                if role == \"model\" and \"text\" in part and not gt:\n",
        "                    gt = str(part[\"text\"])\n",
        "    if img_uri and not mime_type:\n",
        "        mime_type = _guess_mime(img_uri)\n",
        "    return q_text.strip(), img_uri, mime_type, gt.strip()\n",
        "\n",
        "def _load_prediction(jsonl_path: str, idx: int = 0):\n",
        "    \"\"\"Read 'predicted_answer' for row idx from a JSONL results file.\"\"\"\n",
        "    if not os.path.exists(jsonl_path):\n",
        "        return None\n",
        "    with open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for i, line in enumerate(f):\n",
        "            if i == idx:\n",
        "                try:\n",
        "                    return json.loads(line).get(\"predicted_answer\", \"\")\n",
        "                except Exception:\n",
        "                    return \"\"\n",
        "    return None\n",
        "\n",
        "def _fetch_image(uri: str):\n",
        "    \"\"\"Return a PIL Image from gs://, http(s)://, or local path.\"\"\"\n",
        "    if not uri:\n",
        "        return None\n",
        "    if uri.startswith(\"gs://\"):\n",
        "        from google.cloud import storage\n",
        "        bucket_name, blob_name = uri[5:].split(\"/\", 1)\n",
        "        tmp_path = f\"/tmp/_preview_{os.path.basename(blob_name)}\"\n",
        "        storage.Client().bucket(bucket_name).blob(blob_name).download_to_filename(tmp_path)\n",
        "        return PILImage.open(tmp_path)\n",
        "    if uri.startswith(\"http\"):\n",
        "        import requests\n",
        "        resp = requests.get(uri, timeout=30)\n",
        "        resp.raise_for_status()\n",
        "        return PILImage.open(io.BytesIO(resp.content))\n",
        "    # assume local file path\n",
        "    return PILImage.open(uri)\n",
        "\n",
        "# --- Grab the first sample ---\n",
        "q_text, img_uri, mime_type, gt = _parse_first_sft(test_path)\n",
        "tuned_pred = _load_prediction(ft_out, 0)\n",
        "base_pred  = _load_prediction(base_out, 0)\n",
        "\n",
        "print(\"Question:\", q_text or \"(none)\")\n",
        "print(\"Image URI:\", img_uri or \"(none)\")\n",
        "print(\"Ground truth:\", gt or \"(none)\")\n",
        "if tuned_pred is not None:\n",
        "    print(\"Tuned prediction:\", tuned_pred)\n",
        "if base_pred is not None:\n",
        "    print(\"Base prediction :\", base_pred)\n",
        "\n",
        "img = _fetch_image(img_uri) if img_uri else None\n",
        "if img:\n",
        "    display(img)\n",
        "else:\n",
        "    print(\"(No image available to display)\")\n"
      ],
      "metadata": {
        "id": "P3DfS00ZsBsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### STEP 9.2 Display results in table - side by side"
      ],
      "metadata": {
        "id": "7XW20KebMn5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 9.2 â€” Compare tuned-vs-base predictions on the first 10 examples\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "ft_out   = \"ocr-vqa-gemini-ft-results.jsonl\"\n",
        "base_out = \"ocr-vqa-gemini-base-results.jsonl\"\n",
        "\n",
        "# Load results\n",
        "def load_jsonl(path):\n",
        "    rows = []\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            rows.append(json.loads(line))\n",
        "    return rows\n",
        "\n",
        "ft_rows   = load_jsonl(ft_out)\n",
        "base_rows = load_jsonl(base_out)\n",
        "\n",
        "ft_df   = pd.DataFrame(ft_rows)\n",
        "base_df = pd.DataFrame(base_rows)\n",
        "\n",
        "# Merge on example_id to align predictions\n",
        "merged = pd.merge(ft_df, base_df, on=\"example_id\", suffixes=(\"_ft\", \"_base\"))\n",
        "\n",
        "# Select top 10 to preview\n",
        "top10 = merged.head(10)[[\n",
        "    \"example_id\",\n",
        "    \"predicted_answer_ft\",\n",
        "    \"predicted_answer_base\",\n",
        "    \"actual_answer_ft\"    # same ground truth; pulled from ft file\n",
        "]].rename(columns={\n",
        "    \"predicted_answer_ft\":   \"Fine-tuned Prediction\",\n",
        "    \"predicted_answer_base\": \"Base Gemini Prediction\",\n",
        "    \"actual_answer_ft\":      \"Actual Answer\"\n",
        "})\n",
        "\n",
        "from IPython.display import display\n",
        "display(top10)\n"
      ],
      "metadata": {
        "id": "n6x-5NjAKik3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}